data=pd.read_csv(r"E:\大创\train0-40.csv",sep=',')

data = data.drop(data.columns[[19]], axis=1)
new_column_names = ['x1', 'x2', 'x5', 'x6', 'x7', 'x9', 'x10', 'x11', 'x12', 'x14', 'x15', 'x16', 'x17', 'x18', 'x20', 'x23', 'x24', 'y'] # 替换成你想要的新列名
data.columns = new_column_names

#根据不同的任务进行删列
data = data.drop(data.columns[[0]], axis=1)
data = data.drop(data.columns[[0]], axis=1)
data = data.drop(data.columns[[0]], axis=1)

data.iloc[:, -1] = np.where(data.iloc[:, -1] > 125, 125, data.iloc[:, -1])
print(data)

data1=pd.read_csv(r"C:\Users\user\随机森林40三分类周期留class_test0.csv",sep=',',header=None)
data1.columns = new_column_names
import numpy as np


#根据不同的任务进行删列
data1 = data1.drop(data1.columns[[0]], axis=1)
data1 = data1.drop(data1.columns[[0]], axis=1)
data1 = data1.drop(data1.columns[[3]], axis=1)
data1.iloc[:, -1] = np.where(data1.iloc[:, -1] > 125, 125, data1.iloc[:, -1])
print(data1)
#df_train['RUL'] = df_train['RUL'].apply(lambda x: min(x, 125))
#df_test['RUL'] = df_test['RUL'].apply(lambda x: min(x, 125))
X=data.iloc[:,:-1]
Y=data.iloc[:,-1]
X_train, X_val, y_train, y_val = train_test_split(X,Y, test_size = 0.4, random_state=22)

#Scale the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)

# Convert the data to TensorFlow tensors
X_train_scaled = tf.convert_to_tensor(X_train_scaled, dtype=tf.float32)
X_test_scaled = tf.convert_to_tensor(X_val_scaled, dtype=tf.float32)
X_train_minmax = scaler.fit_transform(X_train)
X_val_minmax = scaler.transform(X_val)

# Convert the data to TensorFlow tensors
X_train_minmax = tf.convert_to_tensor(X_train_minmax, dtype=tf.float32)
X_val_minmax = tf.convert_to_tensor(X_val_minmax, dtype=tf.float32)
lamda = 5
tf.random.set_seed(22)

# Define the model architecture
seq_model = tf.keras.Sequential([
    tf.keras.layers.Dense(500, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(lamda), input_dim=X_train_scaled.shape[1]),
    tf.keras.layers.Dense(100, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(lamda)),   
    tf.keras.layers.Dense(1, activation='relu')
])
# compile the model
seq_model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss=MeanSquaredError(),
    metrics=[MeanAbsoluteError()]
)


# Train the model
seq_model.fit(X_train_scaled, y_train, epochs=20, batch_size=32, validation_data=(X_val_scaled, y_val), verbose = 2)
# Make predictions on the test set
y_pred_test = seq_model.predict(X_val_scaled, verbose=0)
mse = mean_absolute_error(y_val , y_pred_test)
print(f"The absolute error with test set is {(mse)}\n")
vs = pd.DataFrame({'actual': y_val.tolist(), 'pred': y_pred_test.tolist()})
vs.head()


# Preparing the test set
X_test = data1.iloc[:,:-1]
y_test = data1.iloc[:,-1]
# Applying scaling normzalization to the test set and convert to tensor object
X_test_scaled = scaler.transform(X_test)
X_test_scaled = tf.convert_to_tensor(X_test_scaled, dtype=tf.float32)
# Make predictions on the test set
y_pred_test = seq_model.predict(X_test_scaled, verbose=0)
mse = np.sqrt(mean_squared_error(y_test , y_pred_test))
print(f"The absolute error with test set is {(mse)}\n")
vs = pd.DataFrame({'actual': y_test.tolist(), 'pred': y_pred_test.tolist()})
vs.head()
plt.figure(figsize=(4,4))
plt.scatter(vs['actual'].tolist(), vs['pred'].tolist(), color = 'm', s=.6)
plt.title('actual vs predicted value')
plt.xlabel('actual')
plt.ylabel('predicted')
plt.show()
plt.figure(figsize=(4,4))
plt.scatter(vs['actual'].tolist(), vs['pred'].tolist(), color = 'm', s=.6)
plt.title('actual vs predicted value for val set')
plt.xlabel('actual')
plt.ylabel('predicted')
plt.show()

