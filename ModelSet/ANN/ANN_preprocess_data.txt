# 所需的包:

# pandas
# numpy
# sklearn.model_selection (train_test_split)
# sklearn.preprocessing (StandardScaler)
# tensorflow (tf)

# 参数列表:
# file_path: 数据文件路径
# columns_to_drop: 删除的列的索引列表
# target_upper_limit: 目标变量的上限值
# test_size: 测试集比例
# random_state: 随机状态


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf

def preprocess_data(file_path, columns_to_drop, target_upper_limit, test_size=0.4, random_state=22):
    data = pd.read_csv(file_path, header=None)
    data.drop(columns=columns_to_drop, axis=1, inplace=True)
    data.iloc[:, -1] = np.where(data.iloc[:, -1] > target_upper_limit, target_upper_limit, data.iloc[:, -1])
    
    X = data.iloc[:, :-1]
    Y = data.iloc[:, -1]
    X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=test_size, random_state=random_state)
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    
    return X_train_scaled, y_train, X_val_scaled, y_val, scaler

